{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3620142d-a85e-45a1-8128-3b8fa41c3e6b",
   "metadata": {},
   "source": [
    "# ベンチマークデータセットのGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c0a755-f67b-4d18-949e-87f0ef442932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.4.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.2.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.1\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e96e7ad-a96b-4f5a-a58b-af85fca8c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../codes\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b54d2d-b328-484f-892a-c0aab9d46adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "from model import GCN\n",
    "from train_test import train, test\n",
    "from my_data_train_utils import conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7744ce28-5b1c-4f54-bcfa-0d1f5c6b8dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13b5202-f630-47ff-a6fd-f4e4248e04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6471, Test Acc: 0.6420\n",
      "Epoch: 002, Train Acc: 0.6423, Test Acc: 0.6333\n",
      "Epoch: 003, Train Acc: 0.6494, Test Acc: 0.6440\n",
      "Epoch: 004, Train Acc: 0.6480, Test Acc: 0.6387\n",
      "Epoch: 005, Train Acc: 0.6780, Test Acc: 0.6693\n",
      "Epoch: 006, Train Acc: 0.6694, Test Acc: 0.6580\n",
      "Epoch: 007, Train Acc: 0.6609, Test Acc: 0.6487\n",
      "Epoch: 008, Train Acc: 0.6803, Test Acc: 0.6707\n",
      "Epoch: 009, Train Acc: 0.6766, Test Acc: 0.6640\n",
      "Epoch: 010, Train Acc: 0.6763, Test Acc: 0.6620\n",
      "Epoch: 011, Train Acc: 0.6740, Test Acc: 0.6620\n",
      "Epoch: 012, Train Acc: 0.6769, Test Acc: 0.6700\n",
      "Epoch: 013, Train Acc: 0.6866, Test Acc: 0.6767\n",
      "Epoch: 014, Train Acc: 0.6711, Test Acc: 0.6627\n",
      "Epoch: 015, Train Acc: 0.6660, Test Acc: 0.6567\n",
      "Epoch: 016, Train Acc: 0.6806, Test Acc: 0.6700\n",
      "Epoch: 017, Train Acc: 0.6611, Test Acc: 0.6507\n",
      "Epoch: 018, Train Acc: 0.6743, Test Acc: 0.6667\n",
      "Epoch: 019, Train Acc: 0.6811, Test Acc: 0.6747\n",
      "data/TUDataset/COLLAB/result\n"
     ]
    }
   ],
   "source": [
    "# data load and split\n",
    "\n",
    "names = [\"MUTAG\", \"DD\", \"REDDIT-BINARY\", \"COLLAB\"]\n",
    "names = [\"COLLAB\"]\n",
    "for data_name in names:\n",
    "    dataset = TUDataset(root='data/TUDataset', name=data_name)\n",
    "\n",
    "    torch.manual_seed(12345)\n",
    "    dataset = dataset.shuffle()\n",
    "\n",
    "    train_index = int(0.7 * len(dataset))\n",
    "\n",
    "    train_dataset = dataset[:train_index]\n",
    "    test_dataset = dataset[train_index:]\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    # set model and train\n",
    "    model = GCN(hidden_channels=64, dataset=dataset)\n",
    "    model.to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adagrad(model.parameters(), lr=0.05, eps=1e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, 20):\n",
    "        train(model, train_loader, criterion, optimizer, device, x=\"degree\")\n",
    "        train_acc = test(model, train_loader, device, x=\"degree\")\n",
    "        test_acc = test(model, test_loader, device, x=\"degree\")\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "    # log を保存する\n",
    "    save_dir = \"data/TUDataset/{}/result\".format(data_name)\n",
    "    \"\"\"log の保存\"\"\"\n",
    "    # 保存先ディレクトリの作成\n",
    "    print(save_dir)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # model(重み) の保存\n",
    "    torch.save(model.to(\"cpu\").state_dict(), save_dir + \"/model.pth\")\n",
    "    # 学習結果の保存\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"train_acc\"] = train_accs\n",
    "    df[\"test_acc\"] = test_accs\n",
    "    df.to_csv(save_dir + \"/log.csv\")\n",
    "    # 学習曲線の保存\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(train_accs, label=\"train\")\n",
    "    plt.plot(test_accs, label=\"test\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.savefig(save_dir + \"/learning.png\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    # make conf matrix\n",
    "    conf_matrix(model, test_loader, device, benchmark=True, benchmark_class=dataset.num_classes, x=\"degree\")\n",
    "    plt.savefig(save_dir + \"/conf_matrix.png\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ff378f-184b-43cb-acfa-0511086e6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "\n",
    "data = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d6b399-99c7-49cc-9af7-d90a36d755ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2976b6-7da8-4de2-9425-7f65f9015a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
