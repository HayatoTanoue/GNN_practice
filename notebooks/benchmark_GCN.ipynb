{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3620142d-a85e-45a1-8128-3b8fa41c3e6b",
   "metadata": {},
   "source": [
    "# ベンチマークデータセットのGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c0a755-f67b-4d18-949e-87f0ef442932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.1\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e96e7ad-a96b-4f5a-a58b-af85fca8c85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../codes\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b54d2d-b328-484f-892a-c0aab9d46adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "from model import GCN\n",
    "from train_test import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7744ce28-5b1c-4f54-bcfa-0d1f5c6b8dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c759eb18-7f50-4ba1-942c-73f36a7e9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load and split\n",
    "data_name = \"MUTAG\"\n",
    "dataset = TUDataset(root='data/TUDataset', name=data_name)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_index = int(0.7 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_index]\n",
    "test_dataset = dataset[train_index:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18549ce6-aaf5-4289-abf6-3121ef0b90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 002, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 003, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 004, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 005, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 006, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 007, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 008, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 009, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 010, Train Acc: 0.6718, Test Acc: 0.7018\n",
      "Epoch: 011, Train Acc: 0.7405, Test Acc: 0.7368\n",
      "Epoch: 012, Train Acc: 0.7176, Test Acc: 0.7193\n",
      "Epoch: 013, Train Acc: 0.7481, Test Acc: 0.7719\n",
      "Epoch: 014, Train Acc: 0.7328, Test Acc: 0.7368\n",
      "Epoch: 015, Train Acc: 0.7328, Test Acc: 0.7193\n",
      "Epoch: 016, Train Acc: 0.7252, Test Acc: 0.7544\n",
      "Epoch: 017, Train Acc: 0.7252, Test Acc: 0.7544\n",
      "Epoch: 018, Train Acc: 0.7328, Test Acc: 0.7368\n",
      "Epoch: 019, Train Acc: 0.7405, Test Acc: 0.7368\n"
     ]
    }
   ],
   "source": [
    "# set model and train\n",
    "model = GCN(hidden_channels=64, dataset=dataset)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    train_acc = test(model, train_loader, device)\n",
    "    test_acc = test(model, test_loader, device)\n",
    "    \n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f00f7e50-e556-4e24-806a-5f06da55fc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/TUDataset/MUTAG/result\n"
     ]
    }
   ],
   "source": [
    "# log を保存する\n",
    "save_dir = \"data/TUDataset/{}/result\".format(data_name)\n",
    "\"\"\"log の保存\"\"\"\n",
    "# 保存先ディレクトリの作成\n",
    "print(save_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# model(重み) の保存\n",
    "torch.save(model.to(\"cpu\").state_dict(), save_dir + \"/model.pth\")\n",
    "# 学習結果の保存\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"train_acc\"] = train_accs\n",
    "df[\"test_acc\"] = test_accs\n",
    "df.to_csv(save_dir + \"/log.csv\")\n",
    "# 学習曲線の保存\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(train_accs, label=\"train\")\n",
    "plt.plot(test_accs, label=\"test\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.savefig(save_dir + \"/learning.png\")\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13b5202-f630-47ff-a6fd-f4e4248e04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 002, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 003, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 004, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 005, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 006, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 007, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 008, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 009, Train Acc: 0.6565, Test Acc: 0.6842\n",
      "Epoch: 010, Train Acc: 0.6718, Test Acc: 0.7018\n",
      "Epoch: 011, Train Acc: 0.7405, Test Acc: 0.7368\n",
      "Epoch: 012, Train Acc: 0.7176, Test Acc: 0.7193\n",
      "Epoch: 013, Train Acc: 0.7481, Test Acc: 0.7719\n",
      "Epoch: 014, Train Acc: 0.7328, Test Acc: 0.7368\n",
      "Epoch: 015, Train Acc: 0.7328, Test Acc: 0.7193\n",
      "Epoch: 016, Train Acc: 0.7252, Test Acc: 0.7544\n",
      "Epoch: 017, Train Acc: 0.7252, Test Acc: 0.7544\n",
      "Epoch: 018, Train Acc: 0.7328, Test Acc: 0.7368\n",
      "Epoch: 019, Train Acc: 0.7405, Test Acc: 0.7368\n",
      "data/TUDataset/MUTAG/result\n",
      "Epoch: 001, Train Acc: 0.5934, Test Acc: 0.5706\n",
      "Epoch: 002, Train Acc: 0.5934, Test Acc: 0.5706\n",
      "Epoch: 003, Train Acc: 0.5959, Test Acc: 0.5706\n",
      "Epoch: 004, Train Acc: 0.5934, Test Acc: 0.5706\n",
      "Epoch: 005, Train Acc: 0.5934, Test Acc: 0.5706\n",
      "Epoch: 006, Train Acc: 0.6845, Test Acc: 0.6921\n",
      "Epoch: 007, Train Acc: 0.6663, Test Acc: 0.6638\n",
      "Epoch: 008, Train Acc: 0.6566, Test Acc: 0.6554\n",
      "Epoch: 009, Train Acc: 0.6869, Test Acc: 0.7034\n",
      "Epoch: 010, Train Acc: 0.6578, Test Acc: 0.6582\n",
      "Epoch: 011, Train Acc: 0.7075, Test Acc: 0.6949\n",
      "Epoch: 012, Train Acc: 0.7124, Test Acc: 0.7175\n",
      "Epoch: 013, Train Acc: 0.7051, Test Acc: 0.7006\n",
      "Epoch: 014, Train Acc: 0.6905, Test Acc: 0.7119\n",
      "Epoch: 015, Train Acc: 0.6930, Test Acc: 0.7090\n",
      "Epoch: 016, Train Acc: 0.7294, Test Acc: 0.7232\n",
      "Epoch: 017, Train Acc: 0.6857, Test Acc: 0.6921\n",
      "Epoch: 018, Train Acc: 0.7318, Test Acc: 0.7260\n",
      "Epoch: 019, Train Acc: 0.7488, Test Acc: 0.7288\n",
      "data/TUDataset/DD/result\n",
      "Epoch: 001, Train Acc: 0.5029, Test Acc: 0.4933\n",
      "Epoch: 002, Train Acc: 0.6914, Test Acc: 0.6683\n",
      "Epoch: 003, Train Acc: 0.6643, Test Acc: 0.6633\n",
      "Epoch: 004, Train Acc: 0.6479, Test Acc: 0.6417\n",
      "Epoch: 005, Train Acc: 0.6679, Test Acc: 0.6700\n",
      "Epoch: 006, Train Acc: 0.6600, Test Acc: 0.6600\n",
      "Epoch: 007, Train Acc: 0.6807, Test Acc: 0.6700\n",
      "Epoch: 008, Train Acc: 0.6750, Test Acc: 0.6617\n",
      "Epoch: 009, Train Acc: 0.6779, Test Acc: 0.6550\n",
      "Epoch: 010, Train Acc: 0.6771, Test Acc: 0.6667\n",
      "Epoch: 011, Train Acc: 0.6836, Test Acc: 0.6667\n",
      "Epoch: 012, Train Acc: 0.6800, Test Acc: 0.6750\n",
      "Epoch: 013, Train Acc: 0.6793, Test Acc: 0.6650\n",
      "Epoch: 014, Train Acc: 0.6714, Test Acc: 0.6450\n",
      "Epoch: 015, Train Acc: 0.6471, Test Acc: 0.6450\n",
      "Epoch: 016, Train Acc: 0.6771, Test Acc: 0.6583\n",
      "Epoch: 017, Train Acc: 0.6800, Test Acc: 0.6683\n",
      "Epoch: 018, Train Acc: 0.6786, Test Acc: 0.6767\n",
      "Epoch: 019, Train Acc: 0.6771, Test Acc: 0.6600\n",
      "data/TUDataset/REDDIT-BINARY/result\n",
      "Epoch: 001, Train Acc: 0.5180, Test Acc: 0.5247\n",
      "Epoch: 002, Train Acc: 0.6186, Test Acc: 0.6180\n",
      "Epoch: 003, Train Acc: 0.6383, Test Acc: 0.6360\n",
      "Epoch: 004, Train Acc: 0.5943, Test Acc: 0.6027\n",
      "Epoch: 005, Train Acc: 0.6714, Test Acc: 0.6800\n",
      "Epoch: 006, Train Acc: 0.6297, Test Acc: 0.6327\n",
      "Epoch: 007, Train Acc: 0.6677, Test Acc: 0.6627\n",
      "Epoch: 008, Train Acc: 0.6549, Test Acc: 0.6367\n",
      "Epoch: 009, Train Acc: 0.6794, Test Acc: 0.6693\n",
      "Epoch: 010, Train Acc: 0.6717, Test Acc: 0.6633\n",
      "Epoch: 011, Train Acc: 0.6574, Test Acc: 0.6553\n",
      "Epoch: 012, Train Acc: 0.6340, Test Acc: 0.6400\n",
      "Epoch: 013, Train Acc: 0.6357, Test Acc: 0.6247\n",
      "Epoch: 014, Train Acc: 0.6737, Test Acc: 0.6533\n",
      "Epoch: 015, Train Acc: 0.6660, Test Acc: 0.6547\n",
      "Epoch: 016, Train Acc: 0.6131, Test Acc: 0.6213\n",
      "Epoch: 017, Train Acc: 0.6243, Test Acc: 0.6193\n",
      "Epoch: 018, Train Acc: 0.6766, Test Acc: 0.6753\n",
      "Epoch: 019, Train Acc: 0.6597, Test Acc: 0.6500\n",
      "data/TUDataset/COLLAB/result\n"
     ]
    }
   ],
   "source": [
    "# data load and split\n",
    "data_name = \"MUTAG\"\n",
    "for data_name in [\"MUTAG\", \"DD\", \"REDDIT-BINARY\", \"COLLAB\"]:\n",
    "    dataset = TUDataset(root='data/TUDataset', name=data_name)\n",
    "\n",
    "    torch.manual_seed(12345)\n",
    "    dataset = dataset.shuffle()\n",
    "\n",
    "    train_index = int(0.7 * len(dataset))\n",
    "\n",
    "    train_dataset = dataset[:train_index]\n",
    "    test_dataset = dataset[train_index:]\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    # set model and train\n",
    "    model = GCN(hidden_channels=64, dataset=dataset)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "\n",
    "\n",
    "    for epoch in range(1, 20):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        train_acc = test(model, train_loader, device)\n",
    "        test_acc = test(model, test_loader, device)\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "    # log を保存する\n",
    "    save_dir = \"data/TUDataset/{}/result\".format(data_name)\n",
    "    \"\"\"log の保存\"\"\"\n",
    "    # 保存先ディレクトリの作成\n",
    "    print(save_dir)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # model(重み) の保存\n",
    "    torch.save(model.to(\"cpu\").state_dict(), save_dir + \"/model.pth\")\n",
    "    # 学習結果の保存\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"train_acc\"] = train_accs\n",
    "    df[\"test_acc\"] = test_accs\n",
    "    df.to_csv(save_dir + \"/log.csv\")\n",
    "    # 学習曲線の保存\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(train_accs, label=\"train\")\n",
    "    plt.plot(test_accs, label=\"test\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.savefig(save_dir + \"/learning.png\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ff378f-184b-43cb-acfa-0511086e6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "\n",
    "data = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d6b399-99c7-49cc-9af7-d90a36d755ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2976b6-7da8-4de2-9425-7f65f9015a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
